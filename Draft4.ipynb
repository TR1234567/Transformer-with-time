{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.sub_modules import GatedResidualNetwork\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import math\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tickers = [\"^GSPC\", \"^IXIC\", \"^TNX\", \"^SPGSCI\", \"^VIX\", \"VTI\"]\n",
    "Crypto = [\"BTC-USD\", \"ETH-USD\", \"BNB-USD\", \"XRP-USD\", \"USDT-USD\"]\n",
    "start=\"2012-01-01\"\n",
    "end=\"2022-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  6 of 6 completed\n",
      "[*********************100%%**********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "Stock_df = yfinance.download(Tickers, start=start, end=end, interval=\"1d\")\n",
    "Crypto_df = yfinance.download(Crypto, start=start, end=end, interval=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stock(df,col):\n",
    "    df = df.fillna(0)\n",
    "    return df[col]\n",
    "def clean_crypto(df,col):\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    return df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/gn4drv5d423127l84w13cgfr0000gn/T/ipykernel_25107/2017961215.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "Stock_df = clean_stock(Stock_df,\"Adj Close\")\n",
    "Crypto_df = clean_crypto(Crypto_df,\"Adj Close\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  6 of 6 completed\n",
      "[*********************100%%**********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "Stock_df_pred = yfinance.download(Tickers, start=end,  interval=\"1d\")\n",
    "Crypto_df_pred = yfinance.download(Crypto, start=end,  interval=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/gn4drv5d423127l84w13cgfr0000gn/T/ipykernel_25107/2017961215.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "Stock_df_pred = clean_stock(Stock_df_pred,\"Adj Close\")\n",
    "Crypto_df_pred = clean_crypto(Crypto_df_pred,\"Adj Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/gn4drv5d423127l84w13cgfr0000gn/T/ipykernel_25107/1571260081.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  after_concat = pd.concat([after,Crypto_df],axis=1).fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "before = Stock_df[:\"2014-09-17\"]\n",
    "after = Stock_df[\"2014-09-17\":]\n",
    "after_concat = pd.concat([after,Crypto_df],axis=1).fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/gn4drv5d423127l84w13cgfr0000gn/T/ipykernel_25107/1277879728.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test = pd.concat([Stock_df_pred,Crypto_df_pred],axis=1).fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "test = pd.concat([Stock_df_pred,Crypto_df_pred],axis=1).fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = before.rolling(1).mean()\n",
    "mu.drop('^VIX',axis=1,inplace=True)\n",
    "returns_tensor = torch.tensor(mu.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu2 = after_concat.rolling(1).mean()\n",
    "mu2.drop('^VIX',axis=1,inplace=True)\n",
    "returns_tensor2 = torch.tensor(mu2.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_test = test.rolling(1).mean()\n",
    "mu_test.drop('^VIX',axis=1,inplace=True)\n",
    "returns_tensor_test = torch.tensor(mu_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vector(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        seq_length = x.size(1)\n",
    "        positions = torch.arange(seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.embed_dim, 2).float() * (-math.log(10000.0) / self.embed_dim))\n",
    "        pos_encoding = torch.zeros(seq_length, self.embed_dim)\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions * div_term)\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions * div_term)\n",
    "        return pos_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SineActivation(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SineActivation, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        print(in_features)\n",
    "        print(out_features)\n",
    "        self.w0 = nn.Parameter(torch.randn(in_features, 1))\n",
    "        self.b0 = nn.Parameter(torch.randn(1))\n",
    "        self.w = nn.Parameter(torch.randn(in_features, out_features - 1))\n",
    "        self.b = nn.Parameter(torch.randn(out_features - 1))\n",
    "        print(\"shape w0\",self.w0.shape)\n",
    "        print(\"shape w\",self.w.shape)\n",
    "        print(\"shape b0\",self.b0.shape)\n",
    "        print(\"shape b\",self.b.shape)\n",
    "    def forward(self, tau, arg=None):\n",
    "        if arg:\n",
    "            v1 = torch.sin(F.linear(tau, self.w, self.b)) * arg\n",
    "        else:\n",
    "            v1 = torch.sin(F.linear(tau, self.w, self.b))\n",
    "\n",
    "        v2 = F.linear(tau, self.w0, self.b0)\n",
    "\n",
    "        return torch.cat([v1, v2], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Time2Vector(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Linear part\n",
    "        self.linear_weights = nn.Parameter(torch.Tensor(self.seq_len))\n",
    "        self.linear_bias = nn.Parameter(torch.Tensor(self.seq_len))\n",
    "\n",
    "        # Periodic part\n",
    "        self.periodic_weights1 = nn.Parameter(torch.Tensor(self.seq_len))\n",
    "        self.periodic_bias1 = nn.Parameter(torch.Tensor(self.seq_len))\n",
    "        self.periodic_weights2 = nn.Parameter(torch.Tensor(self.seq_len))\n",
    "        self.periodic_bias2 = nn.Parameter(torch.Tensor(self.seq_len))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.linear_weights, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.linear_bias, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.periodic_weights1, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.periodic_bias1, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.periodic_weights2, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.periodic_bias2, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Mean reduction across the last dimension\n",
    "        x = torch.mean(x, dim=-1)\n",
    "\n",
    "        # Linear time feature\n",
    "        time_linear = self.linear_weights * x + self.linear_bias\n",
    "        time_linear = time_linear.unsqueeze(-1)\n",
    "\n",
    "        # Periodic time features\n",
    "        time_periodic1 = torch.sin(x * self.periodic_weights1 + self.periodic_bias1)\n",
    "        time_periodic1 = time_periodic1.unsqueeze(-1)\n",
    "        time_periodic2 = torch.sin(x * self.periodic_weights2 + self.periodic_bias2)\n",
    "        time_periodic2 = time_periodic2.unsqueeze(-1)\n",
    "\n",
    "        # Concatenate linear and periodic features\n",
    "        return torch.cat([time_linear, time_periodic1, time_periodic2], dim=-1)\n",
    "    \n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    model2 = PortfolioTransformer(embed_dim=3027,asset_dim_in=11,asset_dim_out=10,nhead=8,num_model=256,batch_size=1)\n",
    "    \"\"\"\n",
    "    def __init__(self, asset_dim_in, num_model,nhead, dropout=0.1,batch_size=1):  # Add input_dim parameter\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.embedding = nn.Linear(asset_dim_in+3, num_model) #asset_dim_in = 11, num_model = 256\n",
    "        self.multihead_attn = nn.MultiheadAttention(num_model, nhead)\n",
    "        self.grn = GatedResidualNetwork(input_size=num_model,hidden_size=num_model,output_size=num_model)\n",
    "        # self.grn = GatedResidualNetwork(d_model, dropout, batch_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(num_model)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.embedding(src)\n",
    "        residual = src\n",
    "        src,_ = self.multihead_attn(src, src, src, attn_mask=src_mask)\n",
    "        src = self.dropout(src)\n",
    "        src = residual + src\n",
    "        src = self.layer_norm(src)\n",
    "\n",
    "        residual = src\n",
    "        src = self.grn(src)\n",
    "        src = self.dropout(src)\n",
    "        src = residual + src\n",
    "        src = self.layer_norm(src)\n",
    "\n",
    "        return src\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, num_model, nhead, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.num_model = num_model\n",
    "        self.masked_mha = nn.MultiheadAttention(num_model, nhead)\n",
    "        self.encoder_attn = nn.MultiheadAttention(num_model, nhead, dropout=dropout)\n",
    "        self.grn = GatedResidualNetwork(input_size=num_model,hidden_size=num_model,output_size=num_model)\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(num_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(num_model)\n",
    "\n",
    "    def forward(self, tgt, memory, src_mask, tgt_mask):\n",
    "        residual = tgt\n",
    "        # Ensure tgt, memory, src_mask, and tgt_mask have the correct dimensions\n",
    "        tgt = tgt.view(tgt.size(0), -1, self.num_model) # Reshape tgt to match the shape of memory\n",
    "        # print(\"this is tgt shape {}\".format(tgt.shape))\n",
    "        memory = memory.view(memory.size(0), -1, self.num_model)\n",
    "        # print(\"this is memory shape {}\".format(memory.shape))\n",
    "        tgt_mask = torch.ones(1,1)\n",
    "\n",
    "        # Transpose tgt for masked_mha\n",
    "        tgt = tgt.transpose(0, 1)\n",
    "\n",
    "        # Masked multi-head attention within decoder\n",
    "        tgt,_ = self.masked_mha(tgt, tgt, tgt, attn_mask=tgt_mask)\n",
    "        # tgt = self.dropout(tgt)\n",
    "\n",
    "        tgt = self.layer_norm1(residual + tgt)\n",
    "\n",
    "        # Transpose tgt back to original order\n",
    "        tgt = tgt.transpose(0, 1)\n",
    "        # print(tgt.shape)\n",
    "        # Multi-head attention to encoder output\n",
    "\n",
    "        tgt= self.encoder_attn(tgt, tgt, memory, attn_mask=src_mask)\n",
    "        # print(tgt[0].shape)\n",
    "        # print(tgt[1].shape)\n",
    "        # tgt = self.dropout(tgt)\n",
    "\n",
    "        tgt = self.layer_norm2(residual + tgt[0])\n",
    "\n",
    "        # Gated residual network\n",
    "        tgt = self.grn(tgt)\n",
    "        # tgt = self.dropout(tgt)\n",
    "        tgt = self.layer_norm2(tgt + residual)\n",
    "\n",
    "        return tgt\n",
    "    \n",
    "class PortfolioLoss(torch.nn.Module):\n",
    "    def __init__(self, cost_rate, risk_free_rate=0.1):\n",
    "        super(PortfolioLoss, self).__init__()\n",
    "        self.cost_rate = cost_rate\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "\n",
    "    def forward(self, weights, returns):\n",
    "        # Ensure weights and returns are in the correct shape\n",
    "        # Weights shape: [batch_size, num_assets]\n",
    "        # Returns shape: [batch_size, num_assets]\n",
    "\n",
    "        # Calculate portfolio returns\n",
    "        # Element-wise multiplication and sum over assets for each instance in the batch\n",
    "        portfolio_returns = torch.sum(weights * returns, dim=1)\n",
    "        \n",
    "        # Calculate portfolio volatility (standard deviation of returns)\n",
    "        # You may need to adjust this calculation depending on how your returns are structured\n",
    "        portfolio_volatility = torch.std(portfolio_returns, dim=0)\n",
    "\n",
    "        # Calculate transaction costs\n",
    "        # Assuming weights are adjacent allocations, calculate the change in weights\n",
    "        deltas = torch.abs(weights[1:] - weights[:-1])\n",
    "        transaction_costs = self.cost_rate * torch.sum(deltas, dim=1)\n",
    "\n",
    "        # Calculate Sharpe Ratio\n",
    "        # Note: risk_free_rate is typically a constant like a treasury bond yield\n",
    "        sharpe_ratio = (portfolio_returns.mean() - self.risk_free_rate) / portfolio_volatility\n",
    "\n",
    "        # Subtract transaction costs\n",
    "        sharpe_ratio -= transaction_costs.mean()\n",
    "        print(\"sharpe_ratio : \",sharpe_ratio)\n",
    "        # Negate Sharpe Ratio to minimize this value during training\n",
    "        cumulative_returns = np.cumprod(1 + returns) - 1\n",
    "        peak, trough = np.argmax(np.maximum.accumulate(cumulative_returns) - cumulative_returns), np.argmax(cumulative_returns)\n",
    "        max_drawdown = cumulative_returns[peak] - cumulative_returns[trough]\n",
    "        average_return = portfolio_returns.mean()\n",
    "        calmar = average_return / abs(max_drawdown)\n",
    "        # return -sharpe_ratio , -calmar , -max_drawdown\n",
    "        return -sharpe_ratio\n",
    "    \n",
    "class PortfolioTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim,asset_dim_in,asset_dim_out,nhead, num_model,batch_size=1):\n",
    "        super(PortfolioTransformer, self).__init__()\n",
    "        self.time2vec = Time2Vector(embed_dim)\n",
    "        self.encoder = EncoderLayer(asset_dim_in=asset_dim_in,num_model=num_model,nhead=nhead,batch_size=batch_size)\n",
    "        self.decoder = DecoderLayer(num_model=num_model,nhead=nhead)\n",
    "        self.linear = nn.Linear(num_model, asset_dim_out)\n",
    "        self.nhead = nhead\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        time_features = self.time2vec(x)\n",
    "        # print(\"X shape \",x.shape)\n",
    "        x = torch.cat([x, time_features], dim=-1)\n",
    "\n",
    "        src_mask = torch.ones(self.nhead, x.shape[0],x.shape[0], dtype=torch.float32)\n",
    "        # print(\"X shape \",x.shape,\"src_mask shape \",src_mask.shape)\n",
    "\n",
    "        x = self.encoder(x, src_mask,)\n",
    "\n",
    "        x = self.decoder(x, x, src_mask, src_mask)\n",
    "        x = self.linear(x)\n",
    "        x = x.mean(dim=1)\n",
    "        # print(\"This is x before softmax\",x)\n",
    "        weights = torch.nn.functional.softmax(x, dim=-1)\n",
    "        print(\"weight of asset shape\",weights.shape)\n",
    "        # print(\"weight of asset\",weights)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_concat_tensor = torch.tensor(after_concat.values, dtype=torch.float32)\n",
    "after_concat_tensor=after_concat_tensor[:374]\n",
    "returns_tensor2 = returns_tensor2[:374]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor(test.values, dtype=torch.float32)\n",
    "test_tensor = test_tensor[:374]\n",
    "returns_tensor_test = returns_tensor_test[:374]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs=10,\n",
    "    embed_dim=374,\n",
    "    asset_dim_in=11,\n",
    "    classes=10,\n",
    "    cost_rate=0.01,\n",
    "    batch_size=1,\n",
    "    learning_rate=0.005,\n",
    "    dataset=\"Price data\",\n",
    "    architecture=\"Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config):\n",
    "\n",
    "    # Make the model\n",
    "    model = PortfolioTransformer(embed_dim=config.embed_dim,asset_dim_in=config.asset_dim_in,asset_dim_out=10,nhead=8,num_model=256,batch_size=1)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, X, returns_tensor, optimizer, config):\n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Run training and track with wandb\n",
    "    total_batches = len(X) * config.epochs\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        loss = train_batch(X, returns_tensor, model, optimizer,config.cost_rate)\n",
    "        example_ct +=  len(X)\n",
    "        batch_ct += 1\n",
    "\n",
    "        # Report metrics every 25th batch\n",
    "        if ((batch_ct + 1) % 25) == 0:\n",
    "            train_log(loss, example_ct, epoch)\n",
    "\n",
    "\n",
    "def train_batch(X, returns_tensor, model, optimizer, cost_rate):\n",
    "    X, returns_tensor = X, returns_tensor\n",
    "    # Forward pass ➡\n",
    "    weights = model(X)\n",
    "    optimizer.zero_grad()\n",
    "    loss = PortfolioLoss(cost_rate=cost_rate)(weights, returns_tensor2)\n",
    "    # sharpe_loss, calmar_loss, max_dd_loss = PortfolioLoss(cost_rate=cost_rate)(weights, returns_tensor2)\n",
    "    # total_loss = 0.7 * sharpe_loss + 0.2 * calmar_loss + 0.1 * max_dd_loss\n",
    "\n",
    "    # total_loss.backward()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # return total_loss,sharpe_loss, calmar_loss, max_dd_loss\n",
    "    gc.collect()\n",
    "    return loss\n",
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"loss\" : loss})\n",
    "    # wandb.log({\"epoch\": epoch, \"total_loss\": total_loss, \"Sharpe_Loss\" : sharpe_loss,\"Calmar Loss\" : calmar_loss, \"Max DD Loss\" : max_dd_loss }, step=example_ct)\n",
    "    # print(f\"Epoch {epoch + 1}/{100}, Total Loss: {total_loss.item():.4f}, Sharpe Loss: {sharpe_loss.item():.4f}, Calmar Loss: {calmar_loss.item():.4f}, Max DD Loss: {max_dd_loss.item():.4f}\")\n",
    "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"Portfolio Transformer\", config=hyperparameters):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      config = wandb.config\n",
    "\n",
    "      # make the model, data, and optimization problem\n",
    "      model, optimizer = make(config)\n",
    "      # print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "      train(model, after_concat_tensor,returns_tensor2, optimizer, config)\n",
    "\n",
    "      # and test its final performance\n",
    "      test_model(model, test_tensor, returns_tensor_test)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, Y, returns_tensor_y):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        Y, returns_tensor_y = Y, returns_tensor_y\n",
    "        weights = model(Y)\n",
    "        loss= PortfolioLoss(cost_rate=0.01)(weights, returns_tensor_y)\n",
    "        wandb.log({\"test_loss\": loss})\n",
    "\n",
    "\n",
    "    # Save the model in the exchangeable ONNX format\n",
    "    torch.onnx.export(model, Y, \"model.onnx\")\n",
    "    wandb.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2771f3a63ae4c4ba4dbaf3408c85a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011137632600083533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/veronicax/Library/Mobile Documents/com~apple~CloudDocs/Python/IS/wandb/run-20240114_124545-f0jw3wj1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/raviel_007/Portfolio%20Transformer/runs/f0jw3wj1' target=\"_blank\">polar-grass-18</a></strong> to <a href='https://wandb.ai/raviel_007/Portfolio%20Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/raviel_007/Portfolio%20Transformer' target=\"_blank\">https://wandb.ai/raviel_007/Portfolio%20Transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/raviel_007/Portfolio%20Transformer/runs/f0jw3wj1' target=\"_blank\">https://wandb.ai/raviel_007/Portfolio%20Transformer/runs/f0jw3wj1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d6c7c79b374511b5d0745a7ad791fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/pc/gn4drv5d423127l84w13cgfr0000gn/T/ipykernel_25107/4237996125.py\", line 13, in model_pipeline\n",
      "    train(model, after_concat_tensor,returns_tensor2, optimizer, config)\n",
      "  File \"/var/folders/pc/gn4drv5d423127l84w13cgfr0000gn/T/ipykernel_25107/1913991516.py\", line 10, in train\n",
      "    loss = train_batch(X, returns_tensor, model, optimizer,config.cost_rate)\n",
      "  File \"/var/folders/pc/gn4drv5d423127l84w13cgfr0000gn/T/ipykernel_25107/1913991516.py\", line 22, in train_batch\n",
      "    weights = model(X)\n",
      "  File \"/Users/veronicax/anaconda3/envs/is/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/veronicax/anaconda3/envs/is/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1568, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/var/folders/pc/gn4drv5d423127l84w13cgfr0000gn/T/ipykernel_25107/4262736333.py\", line 174, in forward\n",
      "    x = torch.cat([x, time_features], dim=-1)\n",
      "RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 374 but got size 11 for tensor number 1 in the list.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2771723415c47ac88b0098bc47df4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-grass-18</strong> at: <a href='https://wandb.ai/raviel_007/Portfolio%20Transformer/runs/f0jw3wj1' target=\"_blank\">https://wandb.ai/raviel_007/Portfolio%20Transformer/runs/f0jw3wj1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240114_124545-f0jw3wj1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 374 but got size 11 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 13\u001b[0m, in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m      9\u001b[0m model, optimizer \u001b[38;5;241m=\u001b[39m make(config)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(model)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# and use them to train the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter_concat_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturns_tensor2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# and test its final performance\u001b[39;00m\n\u001b[1;32m     16\u001b[0m test_model(model, test_tensor, returns_tensor_test)\n",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, X, returns_tensor, optimizer, config)\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_ct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mepochs)):\n\u001b[0;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturns_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     example_ct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mlen\u001b[39m(X)\n\u001b[1;32m     12\u001b[0m     batch_ct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[32], line 22\u001b[0m, in \u001b[0;36mtrain_batch\u001b[0;34m(X, returns_tensor, model, optimizer, cost_rate)\u001b[0m\n\u001b[1;32m     20\u001b[0m X, returns_tensor \u001b[38;5;241m=\u001b[39m X, returns_tensor\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Forward pass ➡\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m PortfolioLoss(cost_rate\u001b[38;5;241m=\u001b[39mcost_rate)(weights, returns_tensor2)\n",
      "File \u001b[0;32m~/anaconda3/envs/is/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/is/lib/python3.10/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 174\u001b[0m, in \u001b[0;36mPortfolioTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m time_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime2vec(x)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# print(\"X shape \",x.shape)\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnhead, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# print(\"X shape \",x.shape,\"src_mask shape \",src_mask.shape)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 374 but got size 11 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "model = model_pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model2\n",
    "learning_rate = 0.001\n",
    "cost_rate = 0.01\n",
    "embed_dim = after_concat_tensor.shape[0]\n",
    "asset_dim_in = after_concat_tensor.shape[1]\n",
    "# Initialize model\"asset_dim, embed_dim, nhead, num_encoder_layers\"\n",
    "model = PortfolioTransformer(embed_dim=embed_dim,asset_dim_in=asset_dim_in,asset_dim_out=10,nhead=8,num_model=256,batch_size=1)\n",
    "# Define optimizer using weight from model1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "#create checkpoint and callback\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./',\n",
    "    filename='model-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    ")\n",
    "# Training loop and add checkpoint and callback\n",
    "for epoch in range(100):\n",
    "\n",
    "    weights = model(after_concat_tensor)\n",
    "    # print(\"thsi is weight output\".format(weights))\n",
    "    # Calculate sharpe ratio loss\n",
    "    # Backpropagate and update parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss = PortfolioLoss(cost_rate=cost_rate)(weights, returns_tensor2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Time2Vector.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([time_linear, time_periodic1, time_periodic2], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTime2Vector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Assuming x is your test set with shape (batch_size, sequence_length)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m x_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m600\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Time2Vector.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Time2Vector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Time2Vector, self).__init__()\n",
    "\n",
    "        # Linear part\n",
    "        self.linear_weights = nn.Parameter(torch.Tensor(1))\n",
    "        self.linear_bias = nn.Parameter(torch.Tensor(1))\n",
    "\n",
    "        # Periodic part\n",
    "        self.periodic_weights1 = nn.Parameter(torch.Tensor(1))\n",
    "        self.periodic_bias1 = nn.Parameter(torch.Tensor(1))\n",
    "        self.periodic_weights2 = nn.Parameter(torch.Tensor(1))\n",
    "        self.periodic_bias2 = nn.Parameter(torch.Tensor(1))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.linear_weights, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.linear_bias, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.periodic_weights1, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.periodic_bias1, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.periodic_weights2, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.periodic_bias2, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Mean reduction across the last dimension\n",
    "        x = torch.mean(x, dim=-1)\n",
    "\n",
    "        seq_len = x.shape[-1]\n",
    "\n",
    "        # Linear time feature\n",
    "        time_linear = self.linear_weights * x + self.linear_bias\n",
    "        time_linear = time_linear.unsqueeze(-1)\n",
    "\n",
    "        # Periodic time features\n",
    "        time_periodic1 = torch.sin(x * self.periodic_weights1 + self.periodic_bias1)\n",
    "        time_periodic1 = time_periodic1.unsqueeze(-1)\n",
    "        time_periodic2 = torch.sin(x * self.periodic_weights2 + self.periodic_bias2)\n",
    "        time_periodic2 = time_periodic2.unsqueeze(-1)\n",
    "\n",
    "        # Concatenate linear and periodic features\n",
    "        return torch.cat([time_linear, time_periodic1, time_periodic2], dim=-1)\n",
    "\n",
    "# Example usage\n",
    "model = Time2Vector()\n",
    "\n",
    "# Assuming x is your test set with shape (batch_size, sequence_length)\n",
    "x_test = torch.rand((10, 600))\n",
    "\n",
    "# Forward pass\n",
    "output = model(x_test)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
